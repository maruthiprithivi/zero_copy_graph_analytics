# Environment Configuration
# This file contains all environment variables for both running the application
# and generating data. Copy this to .env and customize your values.
#
# Setup: cp .env.example .env
#
# Usage:
# - For running the application: Use all sections below
# - For data generation only: Focus on the "Data Generation" section

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================

# ClickHouse Configuration
# For local deployment: CLICKHOUSE_HOST=localhost, CLICKHOUSE_PORT=9000, CLICKHOUSE_SECURE=false
# For cloud deployment: use CLICKHOUSE_HOST_CLOUD values
CLICKHOUSE_HOST_CLOUD=your-instance.clickhouse.cloud
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT_CLOUD=8443
CLICKHOUSE_PORT=9000
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD_CLOUD=your-cloud-password
CLICKHOUSE_PASSWORD=clickhouse123
CLICKHOUSE_DATABASE=customer360
CLICKHOUSE_SECURE=false

# PuppyGraph Configuration
PUPPYGRAPH_HOST=localhost
PUPPYGRAPH_PASSWORD=puppygraph123
PUPPYGRAPH_WEB_PORT=8081
PUPPYGRAPH_GREMLIN_PORT=8182
PUPPYGRAPH_CYPHER_PORT=7687

# Application Settings
STREAMLIT_PORT=8501
STREAMLIT_HOST=0.0.0.0
LOG_LEVEL=INFO
DEBUG_MODE=false
SHOW_PROGRESS_BARS=true
VERBOSE_LOGGING=false

# Data Pipeline Settings
INGESTION_BATCH_SIZE=10000
INGESTION_RETRY_ATTEMPTS=3
INGESTION_RETRY_DELAY=5
CREATE_DATABASE_IF_NOT_EXISTS=true
CHECK_TABLE_EXISTS=true
DROP_EXISTING_TABLES=false
TRUNCATE_BEFORE_LOAD=false
SKIP_EXISTING_TABLES=false

# Performance Settings
MAX_MEMORY_USAGE=4GB
MAX_CPU_CORES=4
CONNECTION_POOL_SIZE=10
QUERY_TIMEOUT=300

# ============================================================================
# DATA GENERATION CONFIGURATION
# ============================================================================

# Customer Scale
CUSTOMER_SCALE=1000000          # Number of customers (100000, 1000000, 10000000, 100000000)

# Data Generation Settings
RANDOM_SEED=42                  # Seed for reproducible data generation (same seed = same data)
                                # Applies to both Customer 360 and Fraud Detection use cases
BATCH_FILE_SIZE=100000          # Records per batch file (for large datasets)
DATA_OUTPUT_DIR=data            # Data output directory
PARQUET_COMPRESSION=snappy      # Parquet compression (snappy, gzip, lz4)
OVERWRITE_EXISTING_DATA=false   # Overwrite existing data files

# Use Cases to Generate
GENERATE_CUSTOMER_360=true      # Generate Customer 360 use case data
GENERATE_FRAUD_DETECTION=true   # Generate Fraud Detection use case data

# Logging
VERBOSE_LOGGING=false           # Enable verbose debug logging
