# Customer 360 Demo Environment Variables
# Copy this file to .env and fill in your actual values

#============================================================================
# ClickHouse Cloud Configuration
#============================================================================
CLICKHOUSE_HOST=abc123.clickhouse.cloud
CLICKHOUSE_PORT=8443  
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=your-password-here
CLICKHOUSE_DATABASE=customer360

#============================================================================
# PuppyGraph Configuration
#============================================================================
PUPPYGRAPH_HOST=localhost
PUPPYGRAPH_PASSWORD=puppygraph123

#============================================================================
# Data Generation Configuration
#============================================================================
GENERATE_DATA=true                      # Enable/disable data generation
CUSTOMER_SCALE=1000000                  # Number of customers (1M, 10M, 100M)
DATA_OUTPUT_DIR=data                    # Output directory for generated data
BATCH_FILE_SIZE=100000                  # Records per batch file (for large datasets)
PARQUET_COMPRESSION=snappy              # Parquet compression: snappy, gzip, lz4
RANDOM_SEED=42                          # Random seed for reproducible data
OVERWRITE_EXISTING_DATA=false           # Overwrite existing data files

#============================================================================
# Data Ingestion Configuration
#============================================================================
INGEST_DATA=true                        # Enable/disable data ingestion
INGESTION_BATCH_SIZE=10000              # Batch size for ClickHouse inserts
CREATE_DATABASE_IF_NOT_EXISTS=true      # Create database if it doesn't exist
CHECK_TABLE_EXISTS=true                 # Check if tables exist before creating
DROP_EXISTING_TABLES=false              # Drop tables before creating (DANGER!)
TRUNCATE_BEFORE_LOAD=false              # Clear existing table data before loading
SKIP_EXISTING_TABLES=false              # Skip ingestion if table has data
INGESTION_RETRY_ATTEMPTS=3              # Number of retry attempts for failed batches
INGESTION_RETRY_DELAY=5                 # Delay between retries (seconds)

#============================================================================
# Operation Mode Configuration
#============================================================================
OPERATION_MODE=both                     # Options: generate, ingest, both
VERBOSE_LOGGING=true                    # Enable detailed logging
SHOW_PROGRESS_BARS=true                 # Show progress bars for long operations
VALIDATE_DATA_AFTER_LOAD=true           # Validate data counts after loading

#============================================================================
# Application Configuration
#============================================================================
STREAMLIT_PORT=8501
STREAMLIT_HOST=0.0.0.0

#============================================================================
# AWS Configuration (for deployment)
#============================================================================
AWS_REGION=us-west-2